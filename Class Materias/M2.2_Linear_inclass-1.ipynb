{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46eed391",
   "metadata": {},
   "source": [
    "## Linear methods for regression and classification\n",
    "In this jupyter notebook, we will practice the topics covered in the lectures. Specially, we will do hands-on practice of:\n",
    "- load and prepare data for machine learning model training and testing\n",
    "- train and test linear models (linear regression (lasso/ridge), polynomial regression, and logistic regression)\n",
    "- compare and understand model performance \n",
    "\n",
    "For implementations that have fixed results, we provide running examples for your reference. *You might get slightly different results due to the sklearn version you are using, just leave a comment to indicate your version where you get different results.*<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5acb55f",
   "metadata": {},
   "source": [
    "## Linear Regression and Polynomial Regression\n",
    "In this section, we will explore the diabetes dataset:\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes <br>\n",
    "\n",
    "This dataset contains n = 442 diabetes patients' information of ten variables: age, sex, body mass index, average blood pressure, and six blood serum measurements. Each patient has a quantitative value of disease progression one year after baseline.\n",
    "\n",
    "\n",
    "We will fit different regression models to analyze this dataset: \n",
    "The steps include:\n",
    "1. Basic data exploration:\n",
    "    > what does the data look like (#samples, #features) <br>\n",
    "    > the feature matrix and description of each feature <br>\n",
    "    > the target variable <br>\n",
    "    \n",
    "2. Prepare data for model training and testing <br>\n",
    "\n",
    "3. Fit different regression models (linear/lasso/ridge) on the training set and evaluate model performance on the testing set <br>\n",
    "\n",
    "4. Compare and understand model performance through interpreting coefficients.\n",
    "\n",
    "**Note:** please always add comments to explain your observations/findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eab86d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6253bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36fb790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are different ways to load the dataset, please make sure you understand the mechanism\n",
    "# reference: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html\n",
    "data = load_diabetes(as_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db355e95",
   "metadata": {},
   "source": [
    "### Basic dataset exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94e585c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((442, 10), (442,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data.shape, data.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83f34331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abcc0287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.018114</td>\n",
       "      <td>0.044485</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.017293</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>-0.046883</td>\n",
       "      <td>0.015491</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.044529</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.073030</td>\n",
       "      <td>-0.081413</td>\n",
       "      <td>0.083740</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.173816</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.004222</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2    0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "439  0.041708  0.050680 -0.015906  0.017293 -0.037344 -0.013840 -0.024993   \n",
       "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       "441 -0.045472 -0.044642 -0.073030 -0.081413  0.083740  0.027809  0.173816   \n",
       "\n",
       "           s4        s5        s6  target  \n",
       "0   -0.002592  0.019907 -0.017646   151.0  \n",
       "1   -0.039493 -0.068332 -0.092204    75.0  \n",
       "2   -0.002592  0.002861 -0.025930   141.0  \n",
       "3    0.034309  0.022688 -0.009362   206.0  \n",
       "4   -0.002592 -0.031988 -0.046641   135.0  \n",
       "..        ...       ...       ...     ...  \n",
       "437 -0.002592  0.031193  0.007207   178.0  \n",
       "438  0.034309 -0.018114  0.044485   104.0  \n",
       "439 -0.011080 -0.046883  0.015491   132.0  \n",
       "440  0.026560  0.044529 -0.025930   220.0  \n",
       "441 -0.039493 -0.004222  0.003064    57.0  \n",
       "\n",
       "[442 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fe381e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "      <td>442.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>152.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>77.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>25.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>87.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>140.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.028</td>\n",
       "      <td>211.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.111</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.136</td>\n",
       "      <td>346.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           age      sex      bmi       bp       s1       s2       s3       s4  \\\n",
       "count  442.000  442.000  442.000  442.000  442.000  442.000  442.000  442.000   \n",
       "mean    -0.000    0.000   -0.000   -0.000   -0.000    0.000   -0.000   -0.000   \n",
       "std      0.048    0.048    0.048    0.048    0.048    0.048    0.048    0.048   \n",
       "min     -0.107   -0.045   -0.090   -0.112   -0.127   -0.116   -0.102   -0.076   \n",
       "25%     -0.037   -0.045   -0.034   -0.037   -0.034   -0.030   -0.035   -0.039   \n",
       "50%      0.005   -0.045   -0.007   -0.006   -0.004   -0.004   -0.007   -0.003   \n",
       "75%      0.038    0.051    0.031    0.036    0.028    0.030    0.029    0.034   \n",
       "max      0.111    0.051    0.171    0.132    0.154    0.199    0.181    0.185   \n",
       "\n",
       "            s5       s6   target  \n",
       "count  442.000  442.000  442.000  \n",
       "mean     0.000    0.000  152.133  \n",
       "std      0.048    0.048   77.093  \n",
       "min     -0.126   -0.138   25.000  \n",
       "25%     -0.033   -0.033   87.000  \n",
       "50%     -0.002   -0.001  140.500  \n",
       "75%      0.032    0.028  211.500  \n",
       "max      0.134    0.136  346.000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(data.frame.describe(),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b3e48c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a histogram to visualize the distribution of the \"target\" value\n",
    "plt.hist(data.frame['target'], rwidth=0.9)\n",
    "plt.title(\"Target value distribution\")\n",
    "plt.xlabel(\"target value\")\n",
    "plt.ylabel(\"#samples\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0964e70",
   "metadata": {},
   "source": [
    "### Prepare data for model training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73f1b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 70% training and 30% testing\n",
    "# Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "# Remember to set random_state to control for the randomness\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5172c982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((309, 10), (133, 10))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check feature matrix\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a796cd9b",
   "metadata": {},
   "source": [
    "### Fit the linear regression model on the training set and evaluate model performance on the testing set \n",
    "> Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3ca436c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.477"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression() # check the documentation to understand the default parameters\n",
    "reg.fit(X_train, y_train)\n",
    "reg_score = reg.score(X_test, y_test)\n",
    "reg_score = np.round(reg_score,3)\n",
    "reg_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92373e7b",
   "metadata": {},
   "source": [
    "**Interpret model coefficients and intercept**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9f93ce14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  29.254, -261.706,  546.3  ,  388.398, -901.96 ,  506.763,\n",
       "        121.154,  288.035,  659.269,   41.377])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_coef = np.round(reg.coef_,3)\n",
    "reg_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f66d6311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151.008"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_int = np.round(reg.intercept_,3)\n",
    "reg_int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a97b88",
   "metadata": {},
   "source": [
    "**Your task**: write down the linear regression model with the above coefficients and intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a435a7",
   "metadata": {},
   "source": [
    "y = 29.245 * x1 + -261.706 * x2 + 546.3 * x3 + 388.398 * x4 + -901.96 * x5 + 506.763 * x6 + 121.154 * x7 + 288.035 * x8 + 659.269 * x9 + \n",
    "41.377 * x10 + 151.008 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baf4c48",
   "metadata": {},
   "source": [
    "**Your task**: explore other parameters/attributes/methods\n",
    "- fit_intercept\n",
    "- feature_names_in_, n_features_in_\n",
    "Write your exploration code and results below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13242258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.102"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using fit_interceppt = Fasle, the default was True\n",
    "reg_new = LinearRegression(fit_intercept=False) \n",
    "reg_new.fit(X_train, y_train)\n",
    "reg_score_new = reg_new.score(X_test, y_test)\n",
    "np.round(reg_score_new,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f1e7df",
   "metadata": {},
   "source": [
    "#### Using feature_names_in_ and n_feature_in_ attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7cd38ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c831dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.n_features_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76d46aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  29.25401303, -261.7064691 ,  546.29972304,  388.39834056,\n",
       "       -901.95966819,  506.76324136,  121.15435079,  288.03526689,\n",
       "        659.26895081,   41.37670105])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc280db1",
   "metadata": {},
   "source": [
    "### Fit and evaluate a Ridge regression model (with the same train/test data)\n",
    "> Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "71a8d3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.423"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rg_reg = Ridge()\n",
    "rg_reg.fit(X_train, y_train)\n",
    "rg_reg_score = rg_reg.score(X_test, y_test)\n",
    "rg_score = np.round(rg_reg_score,3)\n",
    "rg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3c783ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  45.054,  -71.947,  280.716,  195.213,   -2.229,  -17.541,\n",
       "       -148.689,  120.467,  198.614,  106.935])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rg_coef = np.round(rg_reg.coef_,3)\n",
    "rg_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a4deaa4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151.867"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rg_int = np.round(rg_reg.intercept_,3)\n",
    "rg_int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b58d2f",
   "metadata": {},
   "source": [
    "### Your task: fit and evaluate a Lasso regression model (with the same train/test data)\n",
    "> Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c416398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Lasso()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "la_reg = Lasso()\n",
    "la_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "71c90cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.362"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model performance\n",
    "la_reg_score = la_reg.score(X_test, y_test)\n",
    "lasso_score = np.round(la_reg_score,3)\n",
    "lasso_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "78544ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la_reg.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2c5dea51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.   ,  -0.   , 443.703,  51.601,   0.   ,   0.   ,  -0.   ,\n",
       "         0.   , 201.966,   0.   ])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpret model coefficients and intercept\n",
    "lasso_coef = np.round(la_reg.coef_,3)\n",
    "lasso_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d90f8f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_int = np.round(la_reg.intercept_,3)\n",
    "lasso_int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c950962e",
   "metadata": {},
   "source": [
    "### Your task: compare the linear/ridge/lasso regression models\n",
    "- write down your code to create and display the given dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92e90c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear</th>\n",
       "      <th>ridge</th>\n",
       "      <th>lasso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>29.254</td>\n",
       "      <td>45.054</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>-261.706</td>\n",
       "      <td>-71.947</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>546.300</td>\n",
       "      <td>280.716</td>\n",
       "      <td>443.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>388.398</td>\n",
       "      <td>195.213</td>\n",
       "      <td>51.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1</th>\n",
       "      <td>-901.960</td>\n",
       "      <td>-2.229</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s2</th>\n",
       "      <td>506.763</td>\n",
       "      <td>-17.541</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s3</th>\n",
       "      <td>121.154</td>\n",
       "      <td>-148.689</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s4</th>\n",
       "      <td>288.035</td>\n",
       "      <td>120.467</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s5</th>\n",
       "      <td>659.269</td>\n",
       "      <td>198.614</td>\n",
       "      <td>201.966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s6</th>\n",
       "      <td>41.377</td>\n",
       "      <td>106.935</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>151.008</td>\n",
       "      <td>151.867</td>\n",
       "      <td>152.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.477</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            linear    ridge    lasso\n",
       "age         29.254   45.054    0.000\n",
       "sex       -261.706  -71.947   -0.000\n",
       "bmi        546.300  280.716  443.703\n",
       "bp         388.398  195.213   51.601\n",
       "s1        -901.960   -2.229    0.000\n",
       "s2         506.763  -17.541    0.000\n",
       "s3         121.154 -148.689   -0.000\n",
       "s4         288.035  120.467    0.000\n",
       "s5         659.269  198.614  201.966\n",
       "s6          41.377  106.935    0.000\n",
       "intercept  151.008  151.867  152.166\n",
       "score        0.477    0.423    0.362"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hint: the following dataframe shows the expected way to organize and display the information\n",
    "# make sure to: \n",
    "# - round to 3 digits after the decimal point\n",
    "# - rename the column names \n",
    "# - include intercept and score in the last two rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df98619",
   "metadata": {},
   "source": [
    "#### My dataframe coding starts here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a850220c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear</th>\n",
       "      <th>ridge</th>\n",
       "      <th>lasso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>29.254</td>\n",
       "      <td>45.054</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>-261.706</td>\n",
       "      <td>-71.947</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>546.300</td>\n",
       "      <td>280.716</td>\n",
       "      <td>443.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>388.398</td>\n",
       "      <td>195.213</td>\n",
       "      <td>51.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1</th>\n",
       "      <td>-901.960</td>\n",
       "      <td>-2.229</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s2</th>\n",
       "      <td>506.763</td>\n",
       "      <td>-17.541</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s3</th>\n",
       "      <td>121.154</td>\n",
       "      <td>-148.689</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s4</th>\n",
       "      <td>288.035</td>\n",
       "      <td>120.467</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s5</th>\n",
       "      <td>659.269</td>\n",
       "      <td>198.614</td>\n",
       "      <td>201.966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s6</th>\n",
       "      <td>41.377</td>\n",
       "      <td>106.935</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>151.008</td>\n",
       "      <td>151.867</td>\n",
       "      <td>152.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.477</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            linear    ridge    lasso\n",
       "age         29.254   45.054    0.000\n",
       "sex       -261.706  -71.947   -0.000\n",
       "bmi        546.300  280.716  443.703\n",
       "bp         388.398  195.213   51.601\n",
       "s1        -901.960   -2.229    0.000\n",
       "s2         506.763  -17.541    0.000\n",
       "s3         121.154 -148.689   -0.000\n",
       "s4         288.035  120.467    0.000\n",
       "s5         659.269  198.614  201.966\n",
       "s6          41.377  106.935    0.000\n",
       "intercept  151.008  151.867  152.166\n",
       "score        0.477    0.423    0.362"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Lasso data frame\n",
    "lasso_data = {'lasso': lasso_coef}\n",
    "lasso_df = pd.DataFrame(lasso_data, index=la_reg.feature_names_in_)\n",
    "lasso_df.loc['intercept'] = lasso_int\n",
    "lasso_df.loc['score'] = lasso_score\n",
    "lasso_df\n",
    "# Creating ridge data frame\n",
    "rg_data = {'ridge': rg_coef}\n",
    "rg_df = pd.DataFrame(rg_data, index=la_reg.feature_names_in_)\n",
    "rg_df.loc['intercept'] = rg_int\n",
    "rg_df.loc['score'] = rg_score\n",
    "rg_df\n",
    "# Creating linear data frame\n",
    "reg_data = {'linear': reg_coef}\n",
    "reg_df = pd.DataFrame(reg_data, index=la_reg.feature_names_in_)\n",
    "reg_df.loc['intercept'] = reg_int\n",
    "reg_df.loc['score'] = reg_score\n",
    "reg_df\n",
    "# Combining the data frames\n",
    "combined_df = pd.concat([reg_df, rg_df, lasso_df], axis=1)\n",
    "combined_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d7e638",
   "metadata": {},
   "source": [
    "**Your observations and thoughts of comparing the three models**\n",
    "- hint: connect this with what we discussed in the lectures, e.g.\n",
    "    - how does regularization affect coefficients and model performance \n",
    "    - what is the difference between ridge (L2 penalty) and Lasso (L1 penalty) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadf9ec3",
   "metadata": {},
   "source": [
    "1. The first observation that we can draw is on average, the weight of each feature is lowered in ridge and lasso, except for age and s6 in ridge. \n",
    "    - The original linear model contains many large coeffient, while this might be accurate in predicting the original traning data, but it is very prone to overfitting the original data. The small changes will lead to a significant change and it capture noise. Thus we use ridge and lasso to make our model to be more robust to noise and prevent overfitting. This is why we see a decrease in the weight of the features. \n",
    "    - The ridge and lasso regularzation also serving as a balance to reduce the model complexity (i.e. large coeffienct) while maintaining the performance. In this case, we see the score dropped for ridge and lasso because it reduces the coef of the features, but at a cost of the model performance. This is uncommon, for most of the case, ridge and lasso should do a better job on both maintaining the performance while reduce the compleixity. I assume, if the original linear model is well regularized, then applying l1 or l2 could be potentially harmful? \n",
    "2. As we can observe from ridge and lasso, the lasso tends to punish the features that are not important to become 0. In this case, 7 features were transformed into 0s, and it only selected 3 important features. This leads to a sparse representation. Where only a subset of features are selected. In the case of ridge, we see ridge places more punishment on the large weights, it makes them very close to 0 but often not become 0 because it used sqaured. In this case, unlike the 3 features selected by lasso, the ridge contained all of the features, it just that some features are close to 0 such as s1 = -2.229. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cca80a6",
   "metadata": {},
   "source": [
    "## Polynomial regression\n",
    "- Use the diabetes data with the same train and test set to fit several **Polynomial regression** models \n",
    "- documentation: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aaa8fc",
   "metadata": {},
   "source": [
    "### Fit a polynomail regression model with degree=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5c660e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 66)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate the new polynomial feature matrix for the training data \n",
    "# \"fit_transform\" on the original training data\n",
    "\n",
    "poly2 = PolynomialFeatures(2)\n",
    "X_train_poly2 = poly2.fit_transform(X_train)\n",
    "X_train_poly2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "da88debb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 66)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate the new polynomial feature matrix for the testing data \n",
    "# only do \"transform\" on the original testing feature matrix\n",
    "# why do we do \"fit_transform\" on training data but only do \"transform\" on testing data?\n",
    "\n",
    "X_test_poly2 = poly2.transform(X_test)\n",
    "X_test_poly2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3272b97",
   "metadata": {},
   "source": [
    "I guess the reason why we do fit_transform on traning and only transform on testing data is we are only fitting on the original model, and we use the fitted and transformed parameters to predict the testing. We should avoid fitting the testing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "de488def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.413"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit a regression model with the newly generated polynomial feature matrix \n",
    "# evaluate model performance \n",
    "\n",
    "poly2_reg = LinearRegression()\n",
    "poly2_reg.fit(X_train_poly2, y_train)\n",
    "poly2_score = poly2_reg.score(X_test_poly2, y_test)\n",
    "poly2_score = np.round(poly2_score,3)\n",
    "poly2_score "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23561a1",
   "metadata": {},
   "source": [
    "Get intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1d343232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-360.919"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree2_int = np.round(poly2_reg.intercept_,3)\n",
    "degree2_int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72079596",
   "metadata": {},
   "source": [
    "### Your task: fit a polynomail regression model with degree=1\n",
    "- Follow the previous steps of fitting a polynomial regression model with degree=2 to **fit a new model with degree=1** (name it as $poly1\\_reg$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9215fdbb",
   "metadata": {},
   "source": [
    "Transforming the training parameters into degree of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e53f151c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 11)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly1 = PolynomialFeatures(1)\n",
    "X_train_poly1 = poly1.fit_transform(X_train)\n",
    "X_train_poly1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404df570",
   "metadata": {},
   "source": [
    "Transforming the testing into poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "794b0562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 11)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_test_poly1 = poly1.transform(X_test)\n",
    "X_test_poly1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58486d04",
   "metadata": {},
   "source": [
    "Fit and check the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3f9e86ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.477"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "poly1_reg = LinearRegression()\n",
    "poly1_reg.fit(X_train_poly1, y_train)\n",
    "poly1_score = poly1_reg.score(X_test_poly1, y_test)\n",
    "poly1_score = np.round(poly1_score,3)\n",
    "poly1_score "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d665a98",
   "metadata": {},
   "source": [
    "get intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b68e184f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151.008"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree1_int = np.round(poly1_reg.intercept_,3)\n",
    "degree1_int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2b9642",
   "metadata": {},
   "source": [
    "### Your task: fit a polynomail regression model with degree=3\n",
    "- Follow the previous steps of fitting a polynomial regression model with degree=2 to **fit a new model with degree=3** (name it as $poly3\\_reg$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe50ebdf",
   "metadata": {},
   "source": [
    "Transforming the training parameters into degree of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8760be74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 286)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly3 = PolynomialFeatures(3)\n",
    "X_train_poly3 = poly3.fit_transform(X_train)\n",
    "X_train_poly3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f16a5b",
   "metadata": {},
   "source": [
    "Transforming the testing into poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8c0b9490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 286)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_poly3 = poly3.transform(X_test)\n",
    "X_test_poly3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb074f6c",
   "metadata": {},
   "source": [
    "Fit and check the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d29a3915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-92.583"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "poly3_reg = LinearRegression()\n",
    "poly3_reg.fit(X_train_poly3, y_train)\n",
    "poly3_score = poly3_reg.score(X_test_poly3, y_test)\n",
    "poly3_score = np.round(poly3_score,3)\n",
    "poly3_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379de963",
   "metadata": {},
   "source": [
    "get intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "59741ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.371636934848117e+16"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree3_int = np.round(poly3_reg.intercept_,3)\n",
    "degree3_int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc159ab",
   "metadata": {},
   "source": [
    "### Your task: compare the polynomial regression models with degree=1/2/3 and the original linear regression model\n",
    "- please write code to create and display the given data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c2d42873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear</th>\n",
       "      <th>poly_d1</th>\n",
       "      <th>poly_d2</th>\n",
       "      <th>poly_d3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>151.008</td>\n",
       "      <td>151.008</td>\n",
       "      <td>-360.919</td>\n",
       "      <td>2.371637e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.477</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.413</td>\n",
       "      <td>-9.258300e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            linear  poly_d1  poly_d2       poly_d3\n",
       "intercept  151.008  151.008 -360.919  2.371637e+16\n",
       "score        0.477    0.477    0.413 -9.258300e+01"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating linear data frame\n",
    "linear_data = {\n",
    "    'linear': [degree1_int, poly1_score],\n",
    "}\n",
    "linear_df = pd.DataFrame(linear_data, index=['intercept', 'score'])\n",
    "linear_df\n",
    "\n",
    "# Creating poly1 data frame\n",
    "poly1_data = {\n",
    "    'poly_d1': [degree1_int, poly1_score],\n",
    "}\n",
    "poly1_df = pd.DataFrame(poly1_data, index=['intercept', 'score'])\n",
    "poly1_df\n",
    "\n",
    "# Creating poly2 data frame\n",
    "poly2_data = {\n",
    "    'poly_d2': [degree2_int, poly2_score],\n",
    "}\n",
    "poly2_df = pd.DataFrame(poly2_data, index=['intercept', 'score'])\n",
    "poly2_df\n",
    "\n",
    "# Creating poly 3 data frame\n",
    "poly3_data = {\n",
    "    'poly_d3': [degree3_int, poly3_score],\n",
    "}\n",
    "poly3_df = pd.DataFrame(poly3_data, index=['intercept', 'score'])\n",
    "poly3_df\n",
    "\n",
    "combined_poly = pd.concat([linear_df, poly1_df, poly2_df, poly3_df], axis=1)\n",
    "combined_poly\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051b17b2",
   "metadata": {},
   "source": [
    "### Your task: observations and thoughts of comparing the above four models\n",
    "- hint: connect this with overfitting/underfitting we discussed in class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aba6518",
   "metadata": {},
   "source": [
    "1. The poly serves as transforming the original matrix into a poly combination matrix. We use the poly when the original linear model is too simple to predict the relationship, which the original linear regression is just a line, could prone to underfitting the data. \n",
    "2. Here we use the poly function. When the degree = 1, we see the result intercect and score are the same with linear, this is because the degree = 1 (power = 1) is the same with linear regression. \n",
    "3. When we increase the degree, we are essentially making the line to be curve, making it to be more \"flexible\" to predict the complex relationship, however, we need to be cautious, when we increase the degree, it is highly likely to make it to be prone to \"overfitting\".\n",
    "4. degree = 2 shows that we used a poly degree = 2 matrix linear regression to predict the relationship, and the performance actually decreases. \n",
    "    - I think this suggests that degree = 2 is overfitting the data, where a linear regression is already relatively well in predicting the relationship, making it to be higher power may potentially make the model to capture the noise within the data, while the linear regression used the average, could potentailly to some extend to eliminate those noise. \n",
    "5. When we use degree = 3, we see the performance is significantly lower than poly = 2 and linear function. This suggests that a poly = 3 is overfitting the data. And it becomes so complex and started to capture so much noise within the data. I think these models suggest that a linear model is a better fit for this dataset. \n",
    "6. When we use poly matrix linear regression, we could use L1 and L2 to reduce the issue of overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e005bd8",
   "metadata": {},
   "source": [
    "### Your task: interpret the model performance wrt the task itself\n",
    "- how does each feature relate with diabetes\n",
    "- which factors contribute positively/negatively/most/least to diabetes\n",
    "- does these statistical correlations make sense from biological perspective? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7fa311b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear</th>\n",
       "      <th>ridge</th>\n",
       "      <th>lasso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>29.254</td>\n",
       "      <td>45.054</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>-261.706</td>\n",
       "      <td>-71.947</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>546.300</td>\n",
       "      <td>280.716</td>\n",
       "      <td>443.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>388.398</td>\n",
       "      <td>195.213</td>\n",
       "      <td>51.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1</th>\n",
       "      <td>-901.960</td>\n",
       "      <td>-2.229</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s2</th>\n",
       "      <td>506.763</td>\n",
       "      <td>-17.541</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s3</th>\n",
       "      <td>121.154</td>\n",
       "      <td>-148.689</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s4</th>\n",
       "      <td>288.035</td>\n",
       "      <td>120.467</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s5</th>\n",
       "      <td>659.269</td>\n",
       "      <td>198.614</td>\n",
       "      <td>201.966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s6</th>\n",
       "      <td>41.377</td>\n",
       "      <td>106.935</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>151.008</td>\n",
       "      <td>151.867</td>\n",
       "      <td>152.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.477</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            linear    ridge    lasso\n",
       "age         29.254   45.054    0.000\n",
       "sex       -261.706  -71.947   -0.000\n",
       "bmi        546.300  280.716  443.703\n",
       "bp         388.398  195.213   51.601\n",
       "s1        -901.960   -2.229    0.000\n",
       "s2         506.763  -17.541    0.000\n",
       "s3         121.154 -148.689   -0.000\n",
       "s4         288.035  120.467    0.000\n",
       "s5         659.269  198.614  201.966\n",
       "s6          41.377  106.935    0.000\n",
       "intercept  151.008  151.867  152.166\n",
       "score        0.477    0.423    0.362"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e50454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56641a54",
   "metadata": {},
   "source": [
    "Based on the weight table from earlier, it is easily to observe that:\n",
    "1. Age positively contribute to diabetes, suggested by linear and ridge. \n",
    "    - This is because as we age, our body immune system resistance to insulin decreased. And our overall resistance to disease decrease. \n",
    "2. Sex is negatively contribute to diabetes as suggested by linear and ridge. \n",
    "    - Studies have suggest that the difference in hormones such as testostgen and estrogen could affect metabolism. Thus difference in these hormone levels in males and females could affect glucose metabolism, making one sex more prone to diabetes.\n",
    "3. BMI is positively related with diabetes. \n",
    "    - BMI is often asscoiated with obesity, and studies have suggest that higher obesity is related to a decrease repond to insulin, less resisance to insulin is more prone to diabetes. \n",
    "4. Blood pressure is positively related with diabetes. \n",
    "    - Studies have suggest that high blood pressure is often co-exist with diabetes. Diabetes introduces less insulin resistance, can often impair the blood vessels, making the blood pressure abnormal.\n",
    "5. S1 (total serum cholesterol) is negatively related with diabetes. \n",
    "    - higher serum cholesterol is often relate to Dyslipidemia, and Dyslipidemia is often a crucial factor that lead to diabetes. \n",
    "6. S2 (low-density lipoproteins) is positively related with diabetes. \n",
    "    - This is often refer to the bad choleterol, High level of low-density lipoproteins is also link to Dyslipidemia, a key factor that lead to diabetes.\n",
    "7. S3 (high-density lipoproteins), according to ridge, is negatively related with diabetes. \n",
    "    - This makes sense because high-density lipoproteins is associate with improved insulin resistance, thus more resistant to diabetes. \n",
    "8. S4 (total cholesterol / HDL) is positively related to diabetes. \n",
    "    - The ratio is often provide a more comprehensive detail on the relationship of choleterol with high desnity choleterol, as choleterol is a key factor relate to insulin resistance, it makes more sense that it is positively relate to diabetes. \n",
    "9. S5 (possibly log of serum triglycerides level) is positively related to diabetes. \n",
    "    - elevated level of triglycerides level can make the cells to be less reponsive to insulin, thus making the body more prone to diabetes. \n",
    "10. S6 (blood sugar level) is positively related to diabetes. \n",
    "    - The abnormal blood sugar could indicate that there is a disruption of metabolism of sugar within the body, and this is commonly shown in diabetes patients. \n",
    "### BMI, BP, S5(possibly log of serum triglycerides level)\n",
    "- These 3 features seems to positvely contribute to diabetes the most. \n",
    "### Sex, S3 (high-density lipoproteins),S1 (total serum cholesterol)\n",
    "- These 3 features seems to negatively contribute to diabetes the most. \n",
    "### Age and S6 (Blood sugar)\n",
    "- This 1 features seem to contribute to diabetes the least. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef82f53",
   "metadata": {},
   "source": [
    "## Linear models for classification: LogisticRegression \n",
    "In this section, we will work on a banknote authentication dataset:\n",
    "- Original data source: https://archive.ics.uci.edu/ml/datasets/banknote+authentication <br>\n",
    "\n",
    "This dataset contains n = 1372 images of genuine and forged banknote-like specimens. Each image is represented by four features extracted from Wavelet Transform tool: \n",
    "    1. variance (continuous) \n",
    "    2. skewness (continuous)\n",
    "    3. curtosis (continuous)\n",
    "    4. entropy of image (continuous)\n",
    "\n",
    "And each image has a binary label of 0/1 indicating whether the banknote is forged or genuine.\n",
    "\n",
    "We will fit several logistic regression models with different parameter settings to analyze this dataset: \n",
    "The steps include:\n",
    "1. Basic data exploration:\n",
    "    > what does the data look like (#samples, #features) <br>\n",
    "    > the feature matrix and description of each feature <br>\n",
    "    > the target values <br>\n",
    "    \n",
    "2. Prepare data for model training and testing <br>\n",
    "\n",
    "3. Fit different logistic regression models (vary by parameter settings) on the training set and evaluate model performance on the testing set <br>\n",
    "\n",
    "4. Compare and understand model performance through interpreting coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "574468b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cf817f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# please change to your file path\n",
    "df_data = pickle.load(open('./banknote_authentication_dataframe.pickle','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a442ec9",
   "metadata": {},
   "source": [
    "### Basic dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a876742b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.66610</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.16740</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.63830</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.52280</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.40614</td>\n",
       "      <td>1.34920</td>\n",
       "      <td>-1.4501</td>\n",
       "      <td>-0.55949</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>-1.38870</td>\n",
       "      <td>-4.87730</td>\n",
       "      <td>6.4774</td>\n",
       "      <td>0.34179</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-3.75030</td>\n",
       "      <td>-13.45860</td>\n",
       "      <td>17.5932</td>\n",
       "      <td>-2.77710</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>-3.56370</td>\n",
       "      <td>-8.38270</td>\n",
       "      <td>12.3930</td>\n",
       "      <td>-1.28230</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>-2.54190</td>\n",
       "      <td>-0.65804</td>\n",
       "      <td>2.6842</td>\n",
       "      <td>1.19520</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1372 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      variance  skewness  curtosis  entropy  class\n",
       "0      3.62160   8.66610   -2.8073 -0.44699    0.0\n",
       "1      4.54590   8.16740   -2.4586 -1.46210    0.0\n",
       "2      3.86600  -2.63830    1.9242  0.10645    0.0\n",
       "3      3.45660   9.52280   -4.0112 -3.59440    0.0\n",
       "4      0.32924  -4.45520    4.5718 -0.98880    0.0\n",
       "...        ...       ...       ...      ...    ...\n",
       "1367   0.40614   1.34920   -1.4501 -0.55949    1.0\n",
       "1368  -1.38870  -4.87730    6.4774  0.34179    1.0\n",
       "1369  -3.75030 -13.45860   17.5932 -2.77710    1.0\n",
       "1370  -3.56370  -8.38270   12.3930 -1.28230    1.0\n",
       "1371  -2.54190  -0.65804    2.6842  1.19520    1.0\n",
       "\n",
       "[1372 rows x 5 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the dataset\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "222a148c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.433735</td>\n",
       "      <td>1.922353</td>\n",
       "      <td>1.397627</td>\n",
       "      <td>-1.191657</td>\n",
       "      <td>0.444606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.842763</td>\n",
       "      <td>5.869047</td>\n",
       "      <td>4.310030</td>\n",
       "      <td>2.101013</td>\n",
       "      <td>0.497103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7.042100</td>\n",
       "      <td>-13.773100</td>\n",
       "      <td>-5.286100</td>\n",
       "      <td>-8.548200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.773000</td>\n",
       "      <td>-1.708200</td>\n",
       "      <td>-1.574975</td>\n",
       "      <td>-2.413450</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.496180</td>\n",
       "      <td>2.319650</td>\n",
       "      <td>0.616630</td>\n",
       "      <td>-0.586650</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.821475</td>\n",
       "      <td>6.814625</td>\n",
       "      <td>3.179250</td>\n",
       "      <td>0.394810</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.824800</td>\n",
       "      <td>12.951600</td>\n",
       "      <td>17.927400</td>\n",
       "      <td>2.449500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          variance     skewness     curtosis      entropy        class\n",
       "count  1372.000000  1372.000000  1372.000000  1372.000000  1372.000000\n",
       "mean      0.433735     1.922353     1.397627    -1.191657     0.444606\n",
       "std       2.842763     5.869047     4.310030     2.101013     0.497103\n",
       "min      -7.042100   -13.773100    -5.286100    -8.548200     0.000000\n",
       "25%      -1.773000    -1.708200    -1.574975    -2.413450     0.000000\n",
       "50%       0.496180     2.319650     0.616630    -0.586650     0.000000\n",
       "75%       2.821475     6.814625     3.179250     0.394810     1.000000\n",
       "max       6.824800    12.951600    17.927400     2.449500     1.000000"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe the data \n",
    "df_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcbafff",
   "metadata": {},
   "source": [
    "### Prepara data for model training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1fbc714a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1372, 4), (1372,), Counter({0.0: 762, 1.0: 610}))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = ['variance','skewness','curtosis','entropy']\n",
    "\n",
    "# Construct feature matrix from the data frame\n",
    "X_data = df_data[feature_names]\n",
    "y_data = df_data['class']\n",
    "X_data.shape, y_data.shape, Counter(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "98dc3fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((960, 4), (412, 4))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data into 70% training and 30% testing using train_test_split()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3bb9b2",
   "metadata": {},
   "source": [
    "### Fit LogisticRegression models with different parameter settings\n",
    "- L1 VS L2 penalty\n",
    "- C values (inverse of regularization strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2e206acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='liblinear', penalty='l1', C=1.0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cb8b57ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9878640776699029"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0baa21e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2525662f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.   , 0.   ],\n",
       "       [0.982, 0.018],\n",
       "       [0.996, 0.004]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(clf.predict_proba(X_test[:3]),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8ff19c",
   "metadata": {},
   "source": [
    "**Your task**: explore at least one different set of parameters to re-fit the model: solver, penalty, C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1170c6",
   "metadata": {},
   "source": [
    "I am going to set the pentality = 'l2' and C = 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "598e50e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733009708737864"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set parameters and fit\n",
    "clf_new = LogisticRegression(random_state=0, solver='liblinear', penalty='l2', C=0.01).fit(X_train, y_train)\n",
    "\n",
    "# Check performance\n",
    "clf_new.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "20e5af6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(clf_new.coef_[0])\n",
    "max(clf_new.coef_[0])\n",
    "np.mean(np.abs(clf_new.coef_))\n",
    "num_zero_coefficients = np.sum(clf_new.coef_ == 0)\n",
    "num_zero_coefficients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c5d0d1",
   "metadata": {},
   "source": [
    "### Compare model performance with different c values and different penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9160ab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_c(X_train, y_train, X_test, y_test, p):\n",
    "    \"\"\"\n",
    "    X_train/test: 2D feature matrix of training/testing data\n",
    "    y_train/test: 1D array of training/testing labels\n",
    "    p: the penalty parameter setting in LogisticRegression\n",
    "    \n",
    "    return: \n",
    "        a list of classifiers fitted with different c values\n",
    "        a dataframe that is shown in the running example below\n",
    "    \"\"\"\n",
    "     \n",
    "    # set the model parameter c to different values and train the model \n",
    "    # for c in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    #    fit a LogisticRegression model with: the current c value, the given penalty p, set random_state=42, max_iter=1000, solver='liblinear', and use default setting for other parameters\n",
    "    #    test and record the model performance \n",
    "    #    get the statistical information about the model coefficients: \n",
    "    #        min: minimum coefficient\n",
    "    #        max: minimum coefficient\n",
    "    #        mean(abs(coef)): average over the absolute coefficient values\n",
    "    #        n_zero: number of coefficients equal to zero \n",
    "    \n",
    "    ### Your code starts from here \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean_abs</th>\n",
       "      <th>n_zero</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.357</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>-1.581</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>-2.835</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>1.645</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>-5.171</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>2.937</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>-7.648</td>\n",
       "      <td>-0.438</td>\n",
       "      <td>4.297</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000.000</td>\n",
       "      <td>-8.425</td>\n",
       "      <td>-0.482</td>\n",
       "      <td>4.724</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>-8.525</td>\n",
       "      <td>-0.488</td>\n",
       "      <td>4.779</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           c    min    max  mean_abs  n_zero  test_score\n",
       "0      0.001 -0.357 -0.074     0.190       0       0.922\n",
       "1      0.010 -0.861 -0.173     0.485       0       0.973\n",
       "2      0.100 -1.581 -0.163     0.915       0       0.988\n",
       "3      1.000 -2.835 -0.166     1.645       0       0.988\n",
       "4     10.000 -5.171 -0.290     2.937       0       0.988\n",
       "5    100.000 -7.648 -0.438     4.297       0       0.990\n",
       "6   1000.000 -8.425 -0.482     4.724       0       0.990\n",
       "7  10000.000 -8.525 -0.488     4.779       0       0.990"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_c(X_train, y_train, X_test, y_test, p):\n",
    "    results = []\n",
    "    for c in [0.001, 0.01, 0.1, 1, 10, 100,1000,10000]:\n",
    "        clf_new = LogisticRegression(random_state=0, solver='liblinear', penalty=p, C=c)\n",
    "        clf_new.fit(X_train, y_train)\n",
    "        min_coef = np.min(clf_new.coef_[0])\n",
    "        max_coef = np.max(clf_new.coef_[0])\n",
    "        mean_abs_coef = np.mean(np.abs(clf_new.coef_))\n",
    "        num_zero_coefficients = np.sum(clf_new.coef_ == 0)\n",
    "        test_score = clf_new.score(X_test, y_test)\n",
    "        results.append({\n",
    "            'c': c,\n",
    "            'min': min_coef,\n",
    "            'max': max_coef,\n",
    "            'mean_abs': mean_abs_coef,\n",
    "            'n_zero': num_zero_coefficients,\n",
    "            'test_score': test_score\n",
    "        })\n",
    "    results_df = pd.DataFrame(results)\n",
    "    pd.set_option('display.precision',3)\n",
    "    return results_df\n",
    "compare_c(X_train, y_train, X_test, y_test, p='l2')\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "42bbbf61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean_abs</th>\n",
       "      <th>n_zero</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>3</td>\n",
       "      <td>0.624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.807</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.328</td>\n",
       "      <td>1</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>-1.749</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.935</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>-3.852</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>2.172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>-7.081</td>\n",
       "      <td>-0.387</td>\n",
       "      <td>3.977</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>-8.179</td>\n",
       "      <td>-0.463</td>\n",
       "      <td>4.586</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         c    min    max  mean_abs  n_zero  test_score\n",
       "0    0.001 -0.042  0.000     0.010       3       0.624\n",
       "1    0.010 -0.807  0.000     0.328       1       0.917\n",
       "2    0.100 -1.749  0.000     0.935       1       0.988\n",
       "3    1.000 -3.852 -0.133     2.172       0       0.988\n",
       "4   10.000 -7.081 -0.387     3.977       0       0.990\n",
       "5  100.000 -8.179 -0.463     4.586       0       0.990"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_c(X_train, y_train, X_test, y_test, p='l1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934a8855",
   "metadata": {},
   "source": [
    "**Your thoughts and observations:** \n",
    "  - explain model performance from the perspective of under-fitting VS over-fitting\n",
    "  - compare the two tables and indicate the difference between L1 and L2 penalty\n",
    "  - how does c affect coefficients and model performance in each table "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6fd232",
   "metadata": {},
   "source": [
    "1. In this case, a smaller c means more pentality on the complexity and less on the loss. A small C tends to lead to underfitting the data, as we can examine in the table, when we decrease the c to 0.001, the test_score dropped substantially. Meanwhile, if we increase the c, that means we are decreasing the emphasize on regularization, but more emphasis on loss. While we do not examine the effect of overfitting effect in our model, it is highly likely to find the overfitting effect later on because when we increase the value of C, we are not punishing its large weight for potentially overifiting the data, leading our model more prone to noise. \n",
    "2. As we compare the two tables from l1 and l2, we see that ridge does not punish features coef to 0. As shown in table 1, we observe that the max is nearly close to 0 but never reach to 0, as indicated by n_zero, none of the coef were turned into 0s. Whereas in lasso (l1), we seen that when c = 0.001 (large penlty), we seen that 3 features were punished into 0s. Also in l1, when c = 0.01 and 0.1, there both contained features turned into 0 as indicated by n_zero. \n",
    "    - In this data, since we only had 4 features, when we turned 3 features into 0s, we are soley rely on a single feature, that makes our prediction highly inaccurate. \n",
    "    - In addition, we do not see much difference in the performance for both regularization when c > 0.01, but when c = 0.001 we see that lasso turned 3 features into 0, but the performance dropped to 0.624. This means that we did not find a good balance, lasso turned 3 features into 0s at a cost of our performance. Whereas in ridge, we seen that the performance also dropped, but maintained at 0.922, since it punish the large weights. When we set c to be smaller, lasso tends to kill off the features that are useless since we placed a strong emphasis on regularization, this is likely to filter a lot of features. \n",
    "    - We see that lasso serve as a filter, where it filters the useless features whereas ridge punish the large weight features. These two can both be useful depends on our data. \n",
    "3. The smaller the c, the less the mean_abs. This is because when we decrease c, we are placing more emphasis on regularization, that means the overall coef will decerase. The higher the c, the more room we allow for coef, thus the higher mean_abs or overall coef we get. This pattern can also be obversed from min and max, where we see both values in both columns are decerasing as c becomes smaller. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "20e9f8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['variance', 'skewness', 'curtosis', 'entropy'], dtype=object)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_new.feature_names_in_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "75f06f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.86081473, -0.4563506 , -0.45113637, -0.17266226]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_new.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd39d68",
   "metadata": {},
   "source": [
    "### Interpret the model performance wrt the banknote authentication task\n",
    "- how does each feature relate with the identification of genuine and forged banknote\n",
    "- does these statistical correlations make sense from the perspective of image recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b431be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0440979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29bcb91b",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Congratulations for completing this exercise! In this notebook, with hands-on practice of linear models for regression and classification tasks, we gain deep understanding of:\n",
    "- overfitting VS underfitting\n",
    "- difference between l1 and l2 regularizations\n",
    "- the effect of regularization strength on model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327df471",
   "metadata": {},
   "source": [
    "## Which part(s) you find most interesting/chanlleging?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1638e4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
